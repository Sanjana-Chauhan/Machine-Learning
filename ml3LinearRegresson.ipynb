{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "# 1Ô∏è‚É£ What is Linear Regression?\n",
    "Linear Regression is a supervised learning algorithm used to predict a continuous target variable based on one or more independent variables. The goal is to establish a linear relationship between the input features and the target variable by minimizing errors. \n",
    "\n",
    "# 2Ô∏è‚É£ Types of Linear Regression\n",
    "#### Simple Linear Regression: Uses one independent variable to predict the target.  \n",
    "Example:\n",
    "  Predict house price based on size. \n",
    "  Data format: \n",
    "  Size (sq ft) Price \n",
    "  1000 150000 \n",
    "  1500 200000 \n",
    "\n",
    "#### Multiple Linear Regression \n",
    "Uses multiple independent variables to predict the target.  \n",
    "Example: Predict house price based on size, number of bedrooms, and location. \n",
    "Data format:\n",
    "Size Bedrooms Location Price  \n",
    "1000 2 1 150000  \n",
    "1500 3 2 200000   \n",
    "# 3Ô∏è‚É£ Suitable Data Types for Linear Regression  \n",
    "Numerical Data (Continuous or Integer) ‚Äì Required for independent variables (features).  \n",
    "Categorical Data (After Encoding) ‚Äì Can be used after converting to numerical format using techniques like One-Hot Encoding (OHE).   \n",
    "# 4Ô∏è‚É£ Data Preprocessing for Linear Regression \n",
    "To ensure the data is properly formatted and ready for modeling:  \n",
    "#### . Handle Missing Values  \n",
    "   Drop or Impute Missing Data  \n",
    "   data.dropna(inplace=True) # Drop rows with missing values  \n",
    "   or  \n",
    "data.fillna(data.mean(), inplace=True) # Fill with mean/median/mode \n",
    "#### 2. Encode Categorical Variables  \n",
    "One-Hot Encoding (OHE) to convert categorical features into binary variables. \n",
    "from sklearn.preprocessing import OneHotEncoder  \n",
    "ohe = OneHotEncoder(drop='first', sparse=False) # drop='first' to avoid dummy variable trap  \n",
    "encoded_data = pd.get_dummies(data, drop_first=True)  \n",
    "#### 3. Feature Scaling   \n",
    "Scale numerical features for better convergence during model training. \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler()   \n",
    "X_scaled = scaler.fit_transform(X)  \n",
    "# 5Ô∏è‚É£ Splitting Data for Training & Testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.iloc[:, :-1].values # Independent variables \n",
    "y = data.iloc[:, -1].values # Dependent variable \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
    "# 6Ô∏è‚É£ Model Training & Prediction  \n",
    "\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "\n",
    "\n",
    "\n",
    "model = LinearRegression()  \n",
    "model.fit(X_train, y_train)   \n",
    "y_pred = model.predict(X_test)   \n",
    "\n",
    "# 7Ô∏è‚É£ Evaluation Metrics for Linear Regression \n",
    "\n",
    "1. Mean Squared Error (MSE)  \n",
    "   Measures average squared difference between actual and predicted values.\n",
    "   \n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\") \n",
    "2. Root Mean Squared Error (RMSE)\n",
    "Square root of MSE, interpretable in the same units as the target.\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error: {rmse}\") \n",
    "3. Mean Absolute Error (MAE)\n",
    "Average absolute difference between actual and predicted values.\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\") \n",
    "\n",
    "4. R-squared (R¬≤) Score\n",
    "Proportion of variance in the target variable explained by the model.\n",
    "‚Äã\n",
    "from sklearn.metrics import r2_score  \n",
    "r2 = r2_score(y_test, y_pred)  \n",
    "print(f\"R-Squared Score: {r2}\")   \n",
    "\n",
    "# 8Ô∏è‚É£ Model Performance Interpretation\n",
    "MSE/RMSE/MAE: Lower values indicate better fit.   \n",
    "R¬≤ Score:   \n",
    "Close to 1 ‚Üí Good model  \n",
    " Close to 0 ‚Üí Poor model  \n",
    "Negative ‚Üí Worse than random guess  \n",
    "9Ô∏è‚É£ Common Mistakes & Pitfalls to Avoid  \n",
    "‚ùå Overfitting: Model fits training data too well and performs poorly on unseen data.  \n",
    "‚úÖ Solution: Use train-test split and cross-validation.  \n",
    "\n",
    "‚ùå Multicollinearity: High correlation between independent variables leads to instability. \n",
    "‚úÖ Solution: Check correlation matrix and drop correlated features.  \n",
    "\n",
    "‚ùå Ignoring Outliers: Outliers can skew the model.  \n",
    "‚úÖ Solution: Handle outliers using IQR or Z-score methods.  \n",
    "\n",
    "üìö üîü Real-Life Use Cases of Linear Regression  \n",
    "üè° House Price Prediction ‚Äì Predict prices based on features like size, location, etc.   \n",
    "üìà Stock Market Analysis ‚Äì Estimate future stock prices. \n",
    "üöó Car Price Estimation ‚Äì Predict car price using model, mileage, and brand.  \n",
    "üìä Sales Forecasting ‚Äì Predict sales revenue based on historical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"medical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.799874714544996\n",
      "Mean Squared Error: 31845929.134159416\n"
     ]
    }
   ],
   "source": [
    "#Preparing Data\n",
    "encoder=LabelEncoder()\n",
    "data['sex']=encoder.fit_transform(data['sex'])\n",
    "data['smoker']=encoder.fit_transform(data['smoker'])\n",
    "data['region']=encoder.fit_transform(data['region'])\n",
    "\n",
    "#3 Feature Selection\n",
    "X = data.iloc[:, :-1].values  # Features\n",
    "y = data.iloc[:, -1].values   # Target (0 or 1)\n",
    "\n",
    "# Splitting the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#model creation\n",
    "model = LinearRegression()\n",
    "#training the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
